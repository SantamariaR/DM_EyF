import optuna
import lightgbm as lgb
import math
import polars as pl
import pandas as pd
import numpy as np
import logging
import json
import os
from datetime import datetime
from .config import *
from .gain_function import calcular_ganancia, ganancia_evaluator_lgb,ganancia_evaluator_manual, calcular_ganancia_acumulada

logger = logging.getLogger(__name__)


def objetivo_ganancia(trial: optuna.trial.Trial, df: pl.DataFrame, undersampling: float = 1) -> float:
    """
    Parameters:
    trial: trial de optuna
    df: dataframe con datos
  
    Description:
    FunciÃ³n objetivo que maximiza ganancia en mes de validaciÃ³n.
    Utiliza configuraciÃ³n YAML para perÃ­odos y semilla.
    Define parametros para el modelo LightGBM
    Preparar dataset para entrenamiento y validaciÃ³n
    Entrena modelo con funciÃ³n de ganancia personalizada
    Predecir y calcular ganancia
    Guardar cada iteraciÃ³n en JSON
  
    Returns:
    float: ganancia total
    """
  
    periodos_entrenamiento = MES_TRAIN if isinstance(MES_TRAIN, list) else [MES_TRAIN]
    periodo_validacion = MES_VALIDACION
        
    logger.info(f"PerÃ­odos de entrenamiento: {periodos_entrenamiento}")
    logger.info(f"PerÃ­odo de validaciÃ³n: {periodo_validacion}")
        
    df_train = df.filter(pl.col("foto_mes").is_in(periodos_entrenamiento))

    # Separar clases
    df_pos = df_train.filter(pl.col("clase_01") == 1)
    df_neg = df_train.filter(pl.col("clase_01") == 0)

    # Polars no tiene sample(frac=...), pero podemos calcular cuÃ¡ntas filas queremos
    n_sample = int(df_neg.height * undersampling)
    df_neg = df_neg.sample(n=n_sample, seed=SEMILLA[0] + trial.number)

    # Concatenar positivos y negativos muestreados
    df_sub = pl.concat([df_pos, df_neg])

    # Shuffle del dataset
    df_sub = df_sub.sample(fraction=1.0, shuffle=True, seed=SEMILLA[0])
    
    # Preparar datos de validaciÃ³n
    df_val = df.filter(pl.col("foto_mes").is_in(periodo_validacion))

    # ===============================
    # Preparar dataset para LightGBM
    # ===============================
    X = df_sub.drop(["clase_ternaria", "clase_01"]).to_pandas()
    y = df_sub["clase_01"].to_pandas()

    dtrain = lgb.Dataset(X, label=y)
    
    X_val = df_val.drop(["clase_ternaria", "clase_01"]).to_pandas()
    y_val = df_val["clase_01"].to_pandas()
    
    val_data = lgb.Dataset(X_val, label=y_val)
    
    logger.info(f"Train dataset listo: {X.shape}, Pos: {y.sum()}, Neg: {len(y)-y.sum()}")
   
    # Listas para almacenar modelos y predicciones
    modelos = []
    predicciones_val = []
    
    # HIPERPARÃMETROS CON OPTIMIZACIÃ“N BAYESIANA MEJORADA
    cant_registros = X.shape[0]
    
    # ParÃ¡metros con transformaciones similares al cÃ³digo R original
    num_iterations_exp = trial.suggest_float('num_iterations_exp', 0.0, 11.1)
    num_iterations = int(round(2 ** num_iterations_exp))
    
    learning_rate_exp = trial.suggest_float('learning_rate_exp', -8.0, -1.0)
    learning_rate = 2 ** learning_rate_exp
    
    feature_fraction = trial.suggest_float('feature_fraction', 0.05, 1.0)
    
    # min_data_in_leaf con lÃ­mite superior dinÃ¡mico
    max_min_data_exp = math.log2(cant_registros / 2)
    min_data_exp = trial.suggest_float('min_data_exp', 0.0, max_min_data_exp)
    min_data_in_leaf = int(round(2 ** min_data_exp))
    
    num_leaves_exp = trial.suggest_float('num_leaves_exp', 1.0, 10.0)
    num_leaves = int(round(2 ** num_leaves_exp))
    
    # RestricciÃ³n forbidden del cÃ³digo R original
    if min_data_in_leaf * num_leaves > cant_registros:
        logger.info(f"RestricciÃ³n violada: {min_data_in_leaf} * {num_leaves} > {cant_registros}")
        return -1000000  # PenalizaciÃ³n fuerte
    
    params = {
        "boosting": "gbdt",
        "objective": "binary",
        "metric": "None",
        "first_metric_only": False,
        "boost_from_average": True,
        "feature_pre_filter": False,
        "force_row_wise": True,
        "verbosity": -100,
        
        "seed": 143287,
        "feature_fraction_seed": 143287,
        'bagging_seed': 143287,
        "max_depth": -1,
        "min_gain_to_split": 0,
        "min_sum_hessian_in_leaf": 0.001,
        "lambda_l1": 0.0,
        "lambda_l2": 0.0,
        "max_bin": 31,
        
        "bagging_fraction": 1.0,
        "pos_bagging_fraction": 1.0,
        "neg_bagging_fraction": 1.0,
        "is_unbalance": False,
        "scale_pos_weight": 1.0,
        
        "drop_rate": 0.1,
        "max_drop": 50,
        "skip_drop": 0.5,
        
        "extra_trees": False,
        
        # PARÃMETROS OPTIMIZADOS
        "num_iterations": num_iterations,
        "learning_rate": learning_rate,
        "feature_fraction": feature_fraction,
        "min_data_in_leaf": min_data_in_leaf,
        "num_leaves": num_leaves
    }
    
    logger.info(f"ParÃ¡metros del trial: iteraciones={num_iterations}, lr={learning_rate:.6f}, "
                f"feature_frac={feature_fraction:.3f}, min_data={min_data_in_leaf}, leaves={num_leaves}")
    
    # Entrenar 5 modelos con diferentes semillas
    for i, semilla in enumerate(SEMILLA):
        logger.info(f"\n--- Entrenando modelo {i+1} con semilla {semilla} ---")
        
        # Actualizar la semilla en los parÃ¡metros
        params['seed'] = semilla
        params['feature_fraction_seed'] = semilla
        params['bagging_seed'] = semilla
        
        # Entrenar modelo
        model = lgb.train(
            params,
            dtrain,
            valid_sets=[val_data],
            feval=ganancia_evaluator_lgb,
            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]
        )
        
        # Guardar modelo
        modelos.append(model)
        
        # Predecir con este modelo
        y_pred_proba_single = abs(model.predict(X_val))
        predicciones_val.append(y_pred_proba_single)

        # Calcular ganancia individual
        ganancia_individual = ganancia_evaluator_manual(y_val, y_pred_proba_single)  
        logger.info(f"Ganancia modelo {i+1}: {ganancia_individual}")

    # Promediar las predicciones de validaciÃ³n
    y_pred_proba_ensemble = np.mean(predicciones_val, axis=0)
    
    # Calcular ganancia del ensemble
    ganancia_ensemble = ganancia_evaluator_manual(y_val, y_pred_proba_ensemble)
    logger.info(f"\n=== GANANCIA ENSEMBLE: {ganancia_ensemble} ===")    

    # Guardar cada iteraciÃ³n en JSON
    guardar_iteracion(trial, ganancia_ensemble)
  
    logger.info(f"Trial {trial.number}: Ganancia = {ganancia_ensemble:,.0f}")
  
    return ganancia_ensemble



#def objetivo_ganancia(trial: optuna.trial.Trial, df: pl.DataFrame, undersampling: float = 1) -> float:
#    """
#    Parameters:
#    trial: trial de optuna
#    df: dataframe con datos
#  
#    Description:
#    FunciÃ³n objetivo que maximiza ganancia en mes de validaciÃ³n.
#    Utiliza configuraciÃ³n YAML para perÃ­odos y semilla.
#    Define parametros para el modelo LightGBM
#    Preparar dataset para entrenamiento y validaciÃ³n
#    Entrena modelo con funciÃ³n de ganancia personalizada
#    Predecir y calcular ganancia
#    Guardar cada iteraciÃ³n en JSON
#  
#    Returns:
#    float: ganancia total
#    """
#  
#    # Usar target (clase_ternaria ya convertida a binaria)
#  
#    # Features: usar todas las columnas excepto target
#  
#    # Entrenar modelo con funciÃ³n de ganancia personalizada
#    
#    periodos_entrenamiento = MES_TRAIN if isinstance(MES_TRAIN, list) else [MES_TRAIN]
#    periodo_validacion = MES_VALIDACION
#        
#    logger.info(f"PerÃ­odos de entrenamiento: {periodos_entrenamiento}")
#    logger.info(f"PerÃ­odo de validaciÃ³n: {periodo_validacion}")
#        
#    df_train = df.filter(pl.col("foto_mes").is_in(periodos_entrenamiento))
#
#    # Separar clases
#    df_pos = df_train.filter(pl.col("clase_01") == 1)
#    df_neg = df_train.filter(pl.col("clase_01") == 0)
#
#
#    # Polars no tiene sample(frac=...), pero podemos calcular cuÃ¡ntas filas queremos
#    n_sample = int(df_neg.height * undersampling)
#    df_neg = df_neg.sample(n=n_sample, seed=SEMILLA[0] + trial.number)
#
#    # Concatenar positivos y negativos muestreados
#    df_sub = pl.concat([df_pos, df_neg])
#
#    # Shuffle del dataset
#    df_sub = df_sub.sample(fraction=1.0, shuffle=True, seed=SEMILLA[0])
#    
#    # Preparar datos de validaciÃ³n
#    df_val = df.filter(pl.col("foto_mes").is_in(periodo_validacion))
#
#
#    # ===============================
#    # Preparar dataset para LightGBM
#    # ===============================
#    X = df_sub.drop(["clase_ternaria", "clase_01"]).to_pandas()
#    y = df_sub["clase_01"].to_pandas()
#
#    dtrain = lgb.Dataset(X, label=y)
#    
#    X_val = df_val.drop(["clase_ternaria", "clase_01"]).to_pandas()
#    y_val = df_val["clase_01"].to_pandas()
#    
#    val_data = lgb.Dataset(X_val, label=y_val)
#    
#    logger.info(f"Train dataset listo: {X.shape}, Pos: {y.sum()}, Neg: {len(y)-y.sum()} ")
#   
#    # Listas para almacenar modelos y predicciones
#    modelos = []
#    predicciones_val = []
#    # HiperparÃ¡metros a optimizar
#
#    cant_registros = X.shape[0]    
#      
#    params = {
#      "boosting": "gbdt", # puede ir  dart  , ni pruebe random_forest
#      "objective": "binary",
#      "metric": "None",
#      "first_metric_only": False,
#      "boost_from_average": True,
#      "feature_pre_filter": False,
#      "force_row_wise": True, # para reducir warnings
#      "verbosity": -100,
#    
#      "seed": 143287,
#      "feature_fraction_seed": 143287,
#      'bagging_seed': 143287,
#      "max_depth": -1, # -1 significa no limitar,  por ahora lo dejo fijo
#      "min_gain_to_split": 0, # min_gain_to_split >= 0
#      "min_sum_hessian_in_leaf": 0.001, #  min_sum_hessian_in_leaf >= 0.0
#      "lambda_l1": 0.0, # lambda_l1 >= 0.0
#      "lambda_l2": 0.0, # lambda_l2 >= 0.0
#      "max_bin": 31, # lo debo dejar fijo, no participa de la BO
#    
#      "bagging_fraction": 1.0, # 0.0 < bagging_fraction <= 1.0
#      "pos_bagging_fraction": 1.0, # 0.0 < pos_bagging_fraction <= 1.0
#      "neg_bagging_fraction": 1.0,# 0.0 < neg_bagging_fraction <= 1.0
#      "is_unbalance": False, #
#      "scale_pos_weight": 1.0, # scale_pos_weight > 0.0
#    
#      "drop_rate": 0.1, # 0.0 < neg_bagging_fraction <= 1.0
#      "max_drop": 50, # <=0 means no limit
#      "skip_drop": 0.5, # 0.0 <= skip_drop <= 1.0
#    
#      "extra_trees": False,
#    
#      "num_iterations": trial.suggest_int('num_iterations',2048 ,4096 ),
#      "learning_rate": trial.suggest_float('learning_rate', 0.002,0.8 ),
#      "feature_fraction": trial.suggest_float('feature_fraction',0.2 , 0.8),
#      "min_data_in_leaf" : trial.suggest_int('min_data_in_leaf',1 ,2048),
#      "num_leaves": trial.suggest_int('num_leaves', 2, 82)  
#    }
#    
#    # Entrenar 5 modelos con diferentes semillas
#    for i, semilla in enumerate(SEMILLA):
#        logger.info(f"\n--- Entrenando modelo {i+1} con semilla {semilla} ---")
#        
#        # Actualizar la semilla en los parÃ¡metros
#        params['seed'] = semilla
#        params['feature_fraction_seed'] = semilla
#        params['bagging_seed'] = semilla
#        
#        # Entrenar modelo
#        model = lgb.train(
#            params,
#            dtrain,
#            valid_sets=[val_data],
#            feval=ganancia_evaluator_lgb,
#            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]
#        )
#        
#        # Guardar modelo
#        modelos.append(model)
#        
#        # Predecir con este modelo
#        y_pred_proba_single = abs(model.predict(X_val))
#        predicciones_val.append(y_pred_proba_single)
#
#        
#        # Calcular ganancia individual
#        ganancia_individual = ganancia_evaluator_manual(y_val,y_pred_proba_single)  
#        logger.info(f"Ganancia modelo {i+1}: {ganancia_individual}")
#
#    
#    
#    # Promediar las predicciones de validaciÃ³n
#    y_pred_proba_ensemble = np.mean(predicciones_val, axis=0)
#    
#   
#    # Calcular ganancia del ensemble
#    ganancia_ensemble = ganancia_evaluator_manual(y_val, y_pred_proba_ensemble)
#    logger.info(f"\n=== GANANCIA ENSEMBLE: {ganancia_ensemble} ===")    
#
#    # Guardar cada iteraciÃ³n en JSON
#    guardar_iteracion(trial, ganancia_ensemble)
#  
#    logger.info(f"Trial {trial.number}: Ganancia = {ganancia_ensemble:,.0f}")
#  
#    return ganancia_ensemble


#def optimizar(df: pl.DataFrame, n_trials: int = 1) -> optuna.Study:
#    """
#    Ejecuta optimizaciÃ³n bayesiana de hiperparÃ¡metros usando configuraciÃ³n YAML.
#    """
#
#    study_name = STUDY_NAME
#
#    logger.info(f"Iniciando optimizaciÃ³n ")
#    logger.info(f"ConfiguraciÃ³n: perÃ­odos Entrenamiento={MES_TRAIN }, ValidaciÃ³n={MES_VALIDACION}")
#
#     # Crear estudio
#    study = optuna.create_study(
#        direction='maximize',
#        study_name=study_name,
#        sampler=optuna.samplers.TPESampler(seed=SEMILLA[0] if isinstance(SEMILLA, list) else SEMILLA)
#    )
#  
#    # Ejecutar optimizaciÃ³n
#    study.optimize(lambda trial: objetivo_ganancia(trial, df), n_trials=n_trials)
#
##    # NormalizaciÃ³n de parÃ¡metros
##    update_dict = {
##        'min_data_in_leaf': round(study.best_params['min_data_in_leaf'] / HIPERPARAM_BO['UNDERSUMPLING'])
##    }
#    #study.best_params.update(update_dict)
#
#    logger.info(f"Mejor ganancia: {study.best_value:,.0f}")
#    logger.info(f"Mejores parÃ¡metros: {study.best_params}")
#
#    return study


def guardar_iteracion(trial, ganancia, archivo_base=None):
    """
    Guarda cada iteraciÃ³n de la optimizaciÃ³n en un Ãºnico archivo JSON.
  
    Args:
        trial: Trial de Optuna
        ganancia: Valor de ganancia obtenido
        archivo_base: Nombre base del archivo (si es None, usa el de config.yaml)
    """
    if archivo_base is None:
        archivo_base = STUDY_NAME
        
    # Crear carpeta para bases de datos si no existe
    path_db = os.path.join(BUCKET_NAME, "exp")
    os.makedirs(path_db, exist_ok=True)
  
    # Nombre del archivo Ãºnico para todas las iteraciones
    archivo = os.path.join(path_db, f"{archivo_base}_iteraciones.json")
  
    # Datos de esta iteraciÃ³n
    iteracion_data = {
        'trial_number': trial.number,
        'params': trial.params,
        'value': float(ganancia),
        'datetime': datetime.now().isoformat(),
        'state': 'COMPLETE',  # Si llegamos aquÃ­, el trial se completÃ³ exitosamente
        'configuracion': {
            'semilla': SEMILLA,
            'mes_train': MES_TRAIN,
            'mes_validacion': MES_VALIDACION
        }
    }
  
    # Cargar datos existentes si el archivo ya existe
    if os.path.exists(archivo):
        with open(archivo, 'r') as f:
            try:
                datos_existentes = json.load(f)
                if not isinstance(datos_existentes, list):
                    datos_existentes = []
            except json.JSONDecodeError:
                datos_existentes = []
    else:
        datos_existentes = []
  
    # Agregar nueva iteraciÃ³n
    datos_existentes.append(iteracion_data)
  
    # Guardar todas las iteraciones en el archivo
    with open(archivo, 'w') as f:
        json.dump(datos_existentes, f, indent=2)
  
    logger.info(f"IteraciÃ³n {trial.number} guardada en {archivo}")
    logger.info(f"Ganancia: {ganancia:,.0f}" + "---" + "ParÃ¡metros: {params}")



   
def evaluar_en_test(df, mejores_params) -> dict:
    """
    EvalÃºa el modelo con los mejores hiperparÃ¡metros en el conjunto de test.
    Solo calcula la ganancia, sin usar sklearn.
  
    Args:
        df: DataFrame con todos los datos
        mejores_params: Mejores hiperparÃ¡metros encontrados por Optuna
  
    Returns:
        dict: Resultados de la evaluaciÃ³n en test (ganancia + estadÃ­sticas bÃ¡sicas)
    """
    
        # HiperparÃ¡metros a optimizar
    params = {
      "boosting": "gbdt", # puede ir  dart  , ni pruebe random_forest
      "objective": "binary",
      "metric": "None",
      "first_metric_only": False,
      "boost_from_average": True,
      "feature_pre_filter": False,
      "force_row_wise": True, # para reducir warnings
      "verbosity": -100,
    
      "seed": 143287,
      "feature_fraction_seed": 143287,
      'bagging_seed': 143287,
      "max_depth": -1, # -1 significa no limitar,  por ahora lo dejo fijo
      "min_gain_to_split": 0, # min_gain_to_split >= 0
      "min_sum_hessian_in_leaf": 0.001, #  min_sum_hessian_in_leaf >= 0.0
      "lambda_l1": 0.0, # lambda_l1 >= 0.0
      "lambda_l2": 0.0, # lambda_l2 >= 0.0
      "max_bin": 31, # lo debo dejar fijo, no participa de la BO
    
      "bagging_fraction": 1.0, # 0.0 < bagging_fraction <= 1.0
      "pos_bagging_fraction": 1.0, # 0.0 < pos_bagging_fraction <= 1.0
      "neg_bagging_fraction": 1.0,# 0.0 < neg_bagging_fraction <= 1.0
      "is_unbalance": False, #
      "scale_pos_weight": 1.0, # scale_pos_weight > 0.0
    
      "drop_rate": 0.1, # 0.0 < neg_bagging_fraction <= 1.0
      "max_drop": 50, # <=0 means no limit
      "skip_drop": 0.5, # 0.0 <= skip_drop <= 1.0
    
      "extra_trees": False,
    
      "num_iterations": 0,
      "learning_rate": 0,
      "feature_fraction": 0,
      "num_leaves": 0,
      "min_data_in_leaf" : 0  
    }
    
    # Actualizar parÃ¡metros con los sugeridos por Optuna
    params.update(mejores_params)
   
    logger.info("=== EVALUACIÃ“N EN CONJUNTO DE TEST ===")
    logger.info(f"PerÃ­odo de test: {MES_TEST}")
  
    # PerÃ­odos de evaliaciÃ³n
    periodos_entrenamiento = MES_TRAIN + MES_VALIDACION
    #periodo_validacion = MES_VALIDACION
    periodo_test = MES_TEST
        
    logger.info(f"PerÃ­odos de entrenamiento: {periodos_entrenamiento}")
    #logger.info(f"PerÃ­odo de ValidaciÃ³n: {periodo_validacion}")
    logger.info(f"PerÃ­odo de Testeo: {periodo_test}")
 
    # Data preparaciÃ³n, train y test
    df_train = df.filter(pl.col("foto_mes").is_in(periodos_entrenamiento))
    #df_val = df.filter(pl.col("foto_mes").is_in(periodo_validacion))
    df_test = df.filter(pl.col("foto_mes").is_in(periodo_test))
    
    # Separar clases(por si queremos undersampling )
    df_pos = df_train.filter(pl.col("clase_01") == 1)
    df_neg = df_train.filter(pl.col("clase_01") == 0)

    # Concatenar positivos y negativos muestreados
    df_sub = pl.concat([df_pos, df_neg])

    # Shuffle del dataset
    df_sub = df_sub.sample(fraction=1.0, shuffle=True, seed=SEMILLA[0]) 
    

    # ==================================================
    # Preparar dataset para LightGBM, entrenar y testear
    # ==================================================
    X = df_sub.drop(["clase_ternaria", "clase_01"]).to_pandas()
    y = df_sub["clase_01"].to_pandas()

    dtrain = lgb.Dataset(X, label=y)
    
    #X_val = df_val.drop(["clase_ternaria", "clase_01"]).to_pandas()
    #y_val = df_val["clase_01"].to_pandas()
    
    #val_data = lgb.Dataset(X_val, label=y_val) 
    
    # Para test sÃ³lo tomo como positivos BAJA+2
    X_test = df_test.drop(["clase_ternaria", "clase_01"]).to_pandas()
    y_test = df_test["clase_ternaria"].to_pandas()
    y_test = (y_test == "BAJA+3").astype(int)
    
      
    logger.info(f"Train dataset listo: {X.shape}, Pos: {y.sum()}, Neg: {len(y)-y.sum()} ")
   
    # Listas para almacenar modelos y predicciones
    modelos = []
    predicciones_test = []
    # Entrenar 30 modelos con diferentes semillas
    for i, semilla in enumerate(SEMILLA+SEMILLERO):
        logger.info(f"\n--- Entrenando modelo {i+1} con semilla {semilla} ---")
        
        # Actualizar la semilla en los parÃ¡metros
        params['seed'] = semilla
        params['feature_fraction_seed'] = semilla
        params['bagging_seed'] = semilla
        
        # Entrenar modelo
#        model = lgb.train(
#            params,
#            dtrain,
#            feval=ganancia_evaluator_lgb,
#            valid_sets=[val_data],
#            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0),
#            lgb.log_evaluation(period=100)]
#            
#        )
        model = lgb.train(
            params,
            dtrain,
            feval=ganancia_evaluator_lgb,
            num_boost_round=100,  # Especifica el nÃºmero de iteraciones directamente
            callbacks=[lgb.log_evaluation(period=100)]
        )        
        # Guardar modelo
        modelos.append(model)
        
        # Predecir con este modelo
        y_pred_proba_single = abs(model.predict(X_test))
        logger.info(f"Predicciones modelo {i+1} (primeros 10): {y_pred_proba_single[:10]}")
        predicciones_test.append(y_pred_proba_single)    

    # Promediar las predicciones de test
    y_pred_proba_ensemble = np.mean(predicciones_test, axis=0)
    
    # Le aÃ±ado la columna de predicciones al df_test original para anÃ¡lisis posterior si es necesario
    df_test = df_test.with_columns([
        pl.Series("pred_proba_ensemble", y_pred_proba_ensemble)
    ])
    
    #logger.info(f"Datos de test con predicciones listos: {df_test.head()}")
    # Calcular solo la ganancia
    
    # Calculamos las ganancias para distintos cortes
    df_pred = calcular_ganancia_acumulada(df_test, col_probabilidad="pred_proba_ensemble", col_clase="clase_ternaria")
  
 
    return  df_pred

def guardar_resultados_test(df_resultado, archivo_base=None):
    """
    Guarda los resultados de la evaluaciÃ³n en test en un archivo CSV.
    
    Args:
        df_resultado: DataFrame de Polars con la curva de ganancia
        archivo_base: Nombre base del archivo (si es None, usa STUDY_NAME)
    """
    if archivo_base is None:
        archivo_base = STUDY_NAME

    # Crear carpeta para bases de datos si no existe
    path_db = os.path.join(BUCKET_NAME, "exp")
    os.makedirs(path_db, exist_ok=True)
  
    # Nombre del archivo Ãºnico para todas las iteraciones
    archivo_csv = os.path.join(path_db, f"{archivo_base}_test_mes_{MES_TEST}.csv")
    
   
    # Guardar directamente como CSV desde Polars
    df_resultado.write_csv(archivo_csv)
    
    # Me creo un sub de entre 5000 y 30000
    df_reducido = df_resultado.filter(
        (pl.col('cantidad_clientes') >= 0) & (pl.col('cantidad_clientes') <= 30000)
    )
    
    
    # Calcular mÃ©tricas para el log
    ganancia_maxima = df_reducido['ganancia_acumulada'].max()
    cantidad_optima = df_reducido.filter(
        pl.col('ganancia_acumulada') == ganancia_maxima
    )['cantidad_clientes'].min()
    
    logger.info(f"Testeo del MES {MES_TEST} guardado en {archivo_csv}")
    logger.info(f"Ganancia mÃ¡xima: {ganancia_maxima:,.0f} con {cantidad_optima} envÃ­os")
    logger.info(f"Total de registros: {len(df_resultado):,}")



def crear_o_cargar_estudio(study_name: str = None, semilla: int = None) -> optuna.Study:
    """
    Crea un nuevo estudio de Optuna o carga uno existente desde SQLite.
  
    Args:
        study_name: Nombre del estudio (si es None, usa STUDY_NAME del config)
        semilla: Semilla para reproducibilidad
  
    Returns:
        optuna.Study: Estudio de Optuna (nuevo o cargado)
    """
    study_name = STUDY_NAME
    
    
    if semilla is None:
        semilla = SEMILLA[0] if isinstance(SEMILLA, list) else SEMILLA
  
    # Crear carpeta para bases de datos si no existe
    path_db = os.path.join(BUCKET_NAME, "optuna_db")
    os.makedirs(path_db, exist_ok=True)
  
    # Ruta completa de la base de datos
    db_file = os.path.join(path_db, f"{study_name}.db")
    storage = f"sqlite:///{db_file}"
  
    # Verificar si existe un estudio previo
    if os.path.exists(db_file):
        logger.info(f"âš¡ Base de datos encontrada: {db_file}")
        logger.info(f"ğŸ”„ Cargando estudio existente: {study_name}")
  
        try:
            #PRESTAR ATENCION Y RAZONAR!!!
            study = optuna.load_study(study_name=study_name, storage=storage)
            n_trials_previos = len(study.trials)
  
            logger.info(f"âœ… Estudio cargado exitosamente")
            logger.info(f"ğŸ“Š Trials previos: {n_trials_previos}")
  
            if n_trials_previos > 0:
                logger.info(f"ğŸ† Mejor ganancia hasta ahora: {study.best_value:,.0f}")
  
            return study
  
        except Exception as e:
            logger.warning(f"âš ï¸ No se pudo cargar el estudio: {e}")
            logger.info(f"ğŸ†• Creando nuevo estudio...")
    else:
        logger.info(f"ğŸ†• No se encontrÃ³ base de datos previa")
        logger.info(f"ğŸ“ Creando nueva base de datos: {db_file}")
  
     # Crear estudio
    study = optuna.create_study(
        direction='maximize',
        study_name=study_name,
        storage=storage,
        sampler=optuna.samplers.TPESampler(seed=SEMILLA[0] if isinstance(SEMILLA, list) else SEMILLA)
    )

  
    logger.info(f"âœ… Nuevo estudio creado: {study_name}")
    logger.info(f"ğŸ’¾ Storage: {storage}")
  
    return study


def optimizar(df: pd.DataFrame, n_trials: int, study_name: str = None, undersampling: float = 0.01) -> optuna.Study:
    """
    Args:
        df: DataFrame con datos
        n_trials: NÃºmero de trials a ejecutar
        study_name: Nombre del estudio (si es None, usa el de config.yaml)
        undersampling: Undersampling para entrenamiento
  
    Description:
       Ejecuta optimizaciÃ³n bayesiana de hiperparÃ¡metros usando configuraciÃ³n YAML.
       Guarda cada iteraciÃ³n en un archivo JSON separado. 
       Pasos:
        1. Crear estudio de Optuna
        2. Ejecutar optimizaciÃ³n
        3. Retornar estudio

    Returns:
        optuna.Study: Estudio de Optuna con resultados
    """

    study_name = STUDY_NAME
    

    logger.info(f"Iniciando optimizaciÃ³n con {n_trials} trials")
    logger.info(f"ConfiguraciÃ³n: TRAIN={MES_TRAIN}, VALID={MES_VALIDACION}, SEMILLA={SEMILLA}")
  
    # Crear o cargar estudio desde DuckDB
    study = crear_o_cargar_estudio(study_name, SEMILLA)

    # Calcular cuÃ¡ntos trials faltan
    trials_previos = len(study.trials)
    trials_a_ejecutar = max(0, n_trials - trials_previos)
  
    if trials_previos > 0:
        logger.info(f"ğŸ”„ Retomando desde trial {trials_previos}")
        logger.info(f"ğŸ“ Trials a ejecutar: {trials_a_ejecutar} (total objetivo: {n_trials})")
    else:
        logger.info(f"ğŸ†• Nueva optimizaciÃ³n: {n_trials} trials")
  
    # Ejecutar optimizaciÃ³n
    if trials_a_ejecutar > 0:
        ##LO UNICO IMPORTANTE DEL METODO Y EL study CLARO
        study.optimize(lambda trial: objetivo_ganancia(trial, df, undersampling), n_trials=trials_a_ejecutar)
        
        
        logger.info(f"ğŸ† Mejor ganancia: {study.best_value:,.0f}")
        logger.info(f"Mejores parÃ¡metros: {study.best_params}")
    else:
        logger.info(f"âœ… Ya se completaron {n_trials} trials")
        
    # Obtener y mostrar parÃ¡metros transformados
    best_trial = study.best_trial
    
    best_params_transformed = {
        'num_iterations': int(round(2 ** best_trial.params['num_iterations_exp'])),
        'learning_rate': 2 ** best_trial.params['learning_rate_exp'],
        'feature_fraction': best_trial.params['feature_fraction'],
        'min_data_in_leaf': int(round(2 ** best_trial.params['min_data_exp'])),
        'num_leaves': int(round(2 ** best_trial.params['num_leaves_exp']))
    }
    
    # Agregar como atributo custom al estudio
    study.best_params_transformed = best_params_transformed
    
    logger.info(f"ğŸ† Mejor ganancia: {study.best_value:,.0f}")
    logger.info(f"ğŸ“Š ParÃ¡metros EXP: {study.best_params}")
    logger.info(f"ğŸ¯ ParÃ¡metros TRANSFORMADOS: {best_params_transformed}")
    
    return study

